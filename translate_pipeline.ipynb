{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "import time\n",
    "import shutil\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_key = \"your llm api key\"\n",
    "base_url = \"llm server url\"\n",
    "model = \"model name\"\n",
    "client = OpenAI(api_key=llm_api_key, base_url=base_url)\n",
    "mineru_api_key  = \"you can get in https://mineru.net/apiManage/docs\"\n",
    "directory_path = r\"a folder path contains pdf files that you want to translate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you install magic-pdf locally, you can use this function.\n",
    "def process_pdfs_in_dir(dir_path):\n",
    "    search_pattern = os.path.join(dir_path, '**', '*.pdf')\n",
    "    pdf_files = glob.glob(search_pattern, recursive=True)\n",
    "    pdf_files = [pdf_path for pdf_path in pdf_files if not os.path.exists(pdf_path.replace(\".pdf\", \"_zh.md\"))]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"don't find any pdf files\")\n",
    "        return\n",
    "    \n",
    "    output_dir = './output'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for pdf_file in tqdm(pdf_files, desc='processing pdf', unit='file'):\n",
    "        cmd = ['magic-pdf', '-p', pdf_file, '-o', output_dir, '-m', 'txt']\n",
    "        try:\n",
    "            result = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            print(f\"success: {pdf_file}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"error: {pdf_file}, message: {e.stderr.decode().strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_url = 'https://mineru.net/api/v4/file-urls/batch'\n",
    "\n",
    "header = {\n",
    "    'Content-Type': 'application/json',\n",
    "    \"Authorization\": f\"Bearer {mineru_api_key}\"\n",
    "}\n",
    "\n",
    "\n",
    "def base_filename(str):\n",
    "    illegal_chars = r'[\\\\/:*?\"<>|]'\n",
    "    cleaned_name = os.path.basename(str)\n",
    "    cleaned_name = re.sub(illegal_chars, '_', cleaned_name)\n",
    "    cleaned_name = cleaned_name.strip(' ')\n",
    "    return cleaned_name\n",
    "\n",
    "def upload_batch_urls(url_list):\n",
    "    global upload_url, header\n",
    "    data = {\n",
    "        \"language\": \"en\",\n",
    "        \"files\": [\n",
    "            {\"url\": url, 'name': base_filename(url), \"data_id\": \"abcd\"}\n",
    "            for url in url_list\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(upload_url, headers=header, json=data)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print('response success. result:{}'.format(result))\n",
    "            if result[\"code\"] == 0:\n",
    "                batch_id = result[\"data\"][\"batch_id\"]\n",
    "                print('batch_id:{}'.format(batch_id))\n",
    "                return batch_id\n",
    "            else:\n",
    "                raise Exception('submit task failed,reason:{}'.format(result))\n",
    "        else:\n",
    "            raise Exception('response not success. status:{} ,result:{}'.format(response.status_code, response))\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise err\n",
    "\n",
    "def upload_batch_files(pdf_path_list):\n",
    "    global upload_url, header\n",
    "    data = {\n",
    "        \"language\": \"en\",\n",
    "        \"files\": [\n",
    "            {\"name\": base_filename(pdf_path), \"data_id\": \"abcd\"}\n",
    "            for pdf_path in pdf_path_list\n",
    "        ]\n",
    "    }\n",
    "    print(data)\n",
    "\n",
    "    try:\n",
    "        response = requests.post(upload_url, headers=header, json=data)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print('response success. result:{}'.format(result))\n",
    "            if result[\"code\"] == 0:\n",
    "                batch_id = result[\"data\"][\"batch_id\"]\n",
    "                urls = result[\"data\"][\"file_urls\"]\n",
    "                for url_item, pdf_path_item in zip(urls, pdf_path_list):\n",
    "                    with open(pdf_path_item, 'rb') as f:\n",
    "                        res_upload = requests.put(url_item, data=f)\n",
    "                    if res_upload.status_code == 200:\n",
    "                        print(f\"{pdf_path_item} upload success\")\n",
    "                    else:\n",
    "                        print(f\"{pdf_path_item} upload failed\")\n",
    "                print(\"all pdf upload successfully\")\n",
    "                return batch_id\n",
    "            else:\n",
    "                raise Exception('apply upload url failed,reason:{}'.format(result.msg))\n",
    "        else:\n",
    "            raise Exception('response not success. status:{} ,result:{}'.format(response.status_code, response))\n",
    "\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise err\n",
    "    \n",
    "def download_unzip(zip_url, file_name):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        file_name = file_name[:-4]\n",
    "    zip_save_path = os.path.join(\"./zip\", file_name)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(zip_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(zip_save_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        extract_folder = os.path.join(\"./output\", file_name)\n",
    "        if not os.path.exists(extract_folder):\n",
    "            os.makedirs(extract_folder, exist_ok=True)\n",
    "        with zipfile.ZipFile(zip_save_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise e\n",
    "    \n",
    "def monitor_batch(batch_id):\n",
    "    global header\n",
    "    monitor_url = f'https://mineru.net/api/v4/extract-results/batch/{batch_id}'\n",
    "\n",
    "    futures = []\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        while True:\n",
    "            res = requests.get(monitor_url, headers=header).json()['data']\n",
    "            extract_result = res['extract_result']\n",
    "            all_done = True\n",
    "            for result in extract_result:\n",
    "                if result['state'] != 'done':\n",
    "                    all_done = False\n",
    "                    file_log = f\"file_name:{result['file_name']} state: {result['state']}\"\n",
    "                    if result['state'] == 'running':\n",
    "                        file_log += f\" extracted_pages: {result['extract_progress']['extracted_pages']}\"\n",
    "                        file_log += f\" total_pages: {result['extract_progress']['total_pages']}\"\n",
    "                    # print(file_log)\n",
    "                elif result['file_name'] not in [future.result() for future in futures if future.done()]:\n",
    "                    print(result['full_zip_url'])\n",
    "                    futures.append(executor.submit(download_unzip, result['full_zip_url'], result['file_name']))\n",
    "            if all_done:\n",
    "                break\n",
    "            time.sleep(60)\n",
    "\n",
    "def mineru_parser(pdf_path_list=None, url_list=None):\n",
    "    if pdf_path_list:\n",
    "        batch_size = 200\n",
    "        for i in range(0, len(pdf_path_list), batch_size):\n",
    "            batch_paths = pdf_path_list[i:i + batch_size]\n",
    "            files_batch_id = upload_batch_files(batch_paths)\n",
    "            monitor_batch(files_batch_id)\n",
    "\n",
    "    if url_list:\n",
    "        batch_size = 200\n",
    "        for i in range(0, len(url_list), batch_size):\n",
    "            batch_urls = url_list[i:i + batch_size]\n",
    "            url_batch_id = upload_batch_urls(batch_urls)\n",
    "            monitor_batch(url_batch_id)\n",
    "\n",
    "def mineru_parser_directory(directory):\n",
    "    search_pattern = os.path.join(directory, '**', '*.pdf')\n",
    "    pdf_files = glob.glob(search_pattern, recursive=True)\n",
    "    pdf_files = [pdf_path for pdf_path in pdf_files if not os.path.exists(pdf_path.replace(\".pdf\", \"_zh.md\"))]\n",
    "    mineru_parser(pdf_path_list=pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'files': [{'name': '2409.13731v3.pdf', 'data_id': 'abcd'}]}\n",
      "response success. result:{'code': 0, 'msg': 'ok', 'trace_id': '8b0103db8349a82c70e40885f3330fc7', 'data': {'batch_id': '44c8000a-ae8d-449e-be70-51188e8c5dc5', 'file_urls': ['https://mineru.oss-cn-shanghai.aliyuncs.com/api-upload/44c8000a-ae8d-449e-be70-51188e8c5dc5/747b3538-0f1c-47ff-84ac-c65605c3b7e3.pdf?Expires=1740662330&OSSAccessKeyId=LTAI5t9nGwatk85zetzojXbn&Signature=rW91YsJqsKvJ9wi%2BzsYs2elRV9E%3D']}}\n",
      "D:\\Postgraduatev3\\Papers\\my_idea_pdf\\2409.13731v3.pdf upload success\n",
      "all pdf upload successfully\n",
      "https://cdn-mineru.openxlab.org.cn/pdf/33394786-d0c2-4681-87fc-d7ed8f993ba7.zip\n"
     ]
    }
   ],
   "source": [
    "mineru_parser_directory(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_translate(line_str):\n",
    "    line = line_str.strip(\" \\n\")\n",
    "    if line == \"\":\n",
    "        return False\n",
    "    if line.startswith(\"#\"):\n",
    "        return False\n",
    "    if line.startswith(\"![]\"):\n",
    "        return False\n",
    "    if line.startswith(\"$$\"):\n",
    "        return False\n",
    "    if line.startswith(\"<html>\"):\n",
    "        return False\n",
    "    if re.match(r'^\\[[A-Za-z\\s]+[.]?,\\s\\d+[A-Za-z]?\\]', line):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "tranlate_prompt = '''将以下输入的英文文本翻译为中文，请直接输出翻译结果，不附带任何其他的解释和说明格式。。其中，内嵌$和$包围的内嵌latex表达式，不翻译。'''\n",
    "def translate_step(text):\n",
    "    global client, tranlate_prompt, model\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": tranlate_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"输入的英文文本：\\n{text}\"}\n",
    "        ],\n",
    "        stream = False\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def translate(text, retries=1):\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            return translate_step(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Translation attempt {attempt + 1} failed with error: {e}. Retrying...\")\n",
    "            if attempt >= retries:\n",
    "                raise e\n",
    "\n",
    "def process_section(section):\n",
    "    if enable_translate(section):\n",
    "        return translate(section)\n",
    "    else:\n",
    "        return section\n",
    "    \n",
    "def format_figure(str):\n",
    "    pattern = re.compile(r'!\\[(.*?)\\]\\((.*?)\\)')\n",
    "    result = re.sub(pattern, r'![\\1](\\2)\\n\\n', str)\n",
    "    return result\n",
    "\n",
    "def translate_md_files(dir_path):\n",
    "    search_pattern = os.path.join(dir_path, '**', '*.md')\n",
    "    md_files = glob.glob(search_pattern, recursive=True)\n",
    "    md_files = [md_path for md_path in md_files if not md_path.endswith(\"_zh.md\")]\n",
    "    md_files = [md_path for md_path in md_files if not os.path.exists(md_path.replace(\".md\", '_zh.md'))]\n",
    "\n",
    "    for md_path in tqdm(md_files, desc='Processing files', unit='file'):\n",
    "        with open(md_path, encoding='utf-8') as f:\n",
    "            sections = format_figure(f.read()).split(\"\\n\\n\")\n",
    "        output_path = md_path.replace(\".md\", \"_zh.md\")\n",
    "        if os.path.exists(output_path):\n",
    "            continue\n",
    "        translated_sections = [None] * len(sections)\n",
    "        futures = []\n",
    "        max_workers=os.cpu_count()-4\n",
    "        # max_workers=1\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            for idx, section in enumerate(sections):\n",
    "                futures.append((idx, executor.submit(process_section, section)))\n",
    "            for idx, future in futures:\n",
    "                translated_sections[idx] = future.result()\n",
    "\n",
    "        output_content = \"\\n\\n\".join(translated_sections)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(output_content)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1/1 [00:59<00:00, 59.23s/file]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_md_files(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(src_dir, dst_dir):\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "\n",
    "    for file in files:\n",
    "        src_file = os.path.join(src_dir, file)\n",
    "        dst_file = os.path.join(dst_dir, file)\n",
    "        shutil.copy2(src_file, dst_file)\n",
    "\n",
    "def post_return(directory_path):\n",
    "    search_pattern = os.path.join(directory_path, '**', '*.pdf')\n",
    "    pdf_files = glob.glob(search_pattern, recursive=True)\n",
    "    pdf_files = [pdf_path for pdf_path in pdf_files if not os.path.exists(pdf_path.replace(\".pdf\", \"_zh.md\"))]\n",
    "\n",
    "    def copy_file_with_progress(pdf_path):\n",
    "        base_name_with_suffix = os.path.basename(pdf_path)\n",
    "        base_name_without_suffix = base_name_with_suffix[:-4]\n",
    "        target_dir = os.path.dirname(pdf_path)\n",
    "        source_dir = f\"./output/{base_name_without_suffix}\"\n",
    "        if os.path.exists(f\"{source_dir}/txt\"):\n",
    "            source_dir = f\"{source_dir}/txt\"\n",
    "        zh_md_path = glob.glob(os.path.join(source_dir, '*_zh.md'))[0]\n",
    "        # zh_md_path = os.path.join(source_dir, \"full_zh.md\")\n",
    "        new_zh_md_path = pdf_path.replace(\".pdf\", \"_zh.md\")\n",
    "        shutil.copy2(zh_md_path, new_zh_md_path)\n",
    "        source_images_dir = os.path.join(source_dir, \"images\")\n",
    "        target_images_dir = os.path.join(target_dir, \"images\")\n",
    "        os.makedirs(target_images_dir, exist_ok=True)\n",
    "        copy_files(source_images_dir, target_images_dir)\n",
    "        return pdf_path\n",
    "\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()-2) as executor:\n",
    "        futures = {executor.submit(copy_file_with_progress, pdf_path): pdf_path for pdf_path in pdf_files}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc='Copying files'):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Generated an exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 100%|██████████| 1/1 [00:00<00:00, 31.36it/s]\n"
     ]
    }
   ],
   "source": [
    "post_return(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md_filter(text):\n",
    "    text = text.replace(\"<html><body>\", \"\")\n",
    "    text = text.replace(\"</body></html>\", \"\")\n",
    "    text = text.replace(\"•\", \"\\n- \")\n",
    "    return text\n",
    "\n",
    "def post_process_md(directory_path):\n",
    "    search_pattern = os.path.join(directory_path, '**', '*_zh.md')\n",
    "    md_files = glob.glob(search_pattern, recursive=True)\n",
    "    \n",
    "    for file_path in md_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        processed_content = md_filter(content)\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(processed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_md(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_filename(filename):\n",
    "    invalid_chars = r'[<>:\"/\\\\|?*]'\n",
    "    return re.sub(invalid_chars, '', filename)\n",
    "\n",
    "def build_name_dict(directory_path):\n",
    "    result_dict = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('_zh.md'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    first_line = f.readline().strip()\n",
    "                    if first_line.startswith('#'):\n",
    "                        key = os.path.basename(file).replace('_zh.md', '')\n",
    "                        value = clean_filename(first_line[2:])\n",
    "                        result_dict[key] = value\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def rename_dir(directory_path):\n",
    "    result = build_name_dict(directory_path)\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                base_name_without_suffix = os.path.basename(file)[:-4]\n",
    "                if base_name_without_suffix in result:\n",
    "                    old_pdf_path = os.path.join(root, file)\n",
    "                    new_pdf_path = old_pdf_path.replace(base_name_without_suffix, result[base_name_without_suffix])\n",
    "                    os.rename(old_pdf_path, new_pdf_path)\n",
    "                    old_md_path = os.path.join(root, file.replace(\".pdf\", \"_zh.md\"))\n",
    "                    new_md_path = old_md_path.replace(base_name_without_suffix, result[base_name_without_suffix])\n",
    "                    os.rename(old_md_path, new_md_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dir(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MinerU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
